{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT554: OptimalControl 4 ✈️\n",
    "## Assignment 1\n",
    "\n",
    "\n",
    "\n",
    " Name: Anupam Kumar\n",
    " \n",
    " Roll No: 11940160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(x): # x is a numpy array of size 2\n",
    "    res = 0\n",
    "    \n",
    "    res += 2*x[0]**2\n",
    "    res += 4*x[0]*x[1]\n",
    "    res += 4*x[1]**2\n",
    "    res += 2*x[1]\n",
    "    res -= 4*x[0]\n",
    "    res += 16\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_f(x): \n",
    "    res = zeros(2)\n",
    "    res[0] += 4*x[0]\n",
    "    res[0] += 4*x[1]\n",
    "    res[0] -= 4\n",
    "    res[1] += 4*x[0]\n",
    "    res[1] += 8*x[1]\n",
    "    res[1] += 2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_f(x):\n",
    "    res = zeros((2,2))\n",
    "    res[0][0] += 4\n",
    "    res[0][1] += 4\n",
    "    res[1][0] += 4\n",
    "    res[1][1] += 8\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(x0, tol):\n",
    "    x = x0\n",
    "    while True:\n",
    "        x = x - dot(inv(hessian_f(x)), gradient_f(x))\n",
    "        if linalg.norm(gradient_f(x)) < tol:\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to calculate the steepest descent direction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(x, d1, d2, d3, iterations):\n",
    "    for i in range(iterations):\n",
    "        fx = fn(x)\n",
    "        grad = gradient_f(x)\n",
    "        hessian = hessian_f(x)\n",
    "\n",
    "        d_k = -1*grad\n",
    "\n",
    "        lambda_k = -dot(grad.T, d_k)/dot(dot(d_k.T, hessian), d_k)\n",
    "\n",
    "        x = x + lambda_k*d_k\n",
    "\n",
    "        dx = lambda_k*d_k\n",
    "\n",
    "        if abs(fn(x) - fx) < d1:\n",
    "            break\n",
    "\n",
    "        if abs(dot(grad.T, grad)) < d3:\n",
    "            break\n",
    "\n",
    "        if abs(dot(dx.T, dx)) < d2:\n",
    "            break\n",
    "\n",
    "    return x, fn(x), i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value occurs at:  [ 2.49985776 -1.49991466]\n",
      "The minimum value is:  9.500000021041334\n",
      "The number of iterations is:  5\n"
     ]
    }
   ],
   "source": [
    "x, fx, i = steepest_descent(array([0,0]), 0.000001, 0.000001, 0.000001, 10000)\n",
    "print(\"The minimum value occurs at: \", x)\n",
    "\n",
    "print(\"The minimum value is: \", fx)\n",
    "\n",
    "print(\"The number of iterations is: \", i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to calculate the conjugate descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugate_descent(x, d1, d2, d3, iterations):\n",
    "    for i in range(iterations):\n",
    "        fx = fn(x)\n",
    "        grad = gradient_f(x)\n",
    "        hessian = hessian_f(x)\n",
    "        d_k = -1*grad\n",
    "        \n",
    "        grad_prev = grad\n",
    "        beta_k = dot(grad.T, grad)/dot(grad_prev.T, grad_prev)\n",
    "        d_k = -1*grad + beta_k*d_k\n",
    "\n",
    "        lambda_k = -dot(grad.T, d_k)/dot(dot(d_k.T, hessian), d_k)\n",
    "\n",
    "        x = x + lambda_k*d_k\n",
    "\n",
    "        dx = lambda_k*d_k\n",
    "\n",
    "        grad_prev = grad\n",
    "        d_k_prev = d_k\n",
    "\n",
    "        if abs(fn(x) - fx) < d1:\n",
    "            break\n",
    "        \n",
    "        if abs(dot(dx.T, dx)) < d2:\n",
    "            break\n",
    "        \n",
    "        if abs(dot(grad.T, grad)) < d3:\n",
    "            break\n",
    "\n",
    "        \n",
    "\n",
    "    return x, fn(x), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value occurs at:  [ 2.49985776 -1.49991466]\n",
      "The minimum value is:  9.500000021041334\n",
      "The number of iterations is:  5\n"
     ]
    }
   ],
   "source": [
    "x, fx, i = conjugate_descent(array([0,0]), 0.000001, 0.000001, 0.000001, 10000)\n",
    "print(\"The minimum value occurs at: \", x)\n",
    "\n",
    "print(\"The minimum value is: \", fx)\n",
    "\n",
    "print(\"The number of iterations is: \", i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d12a3414d241d65a277b7f30b382402d48a02aa8eae8e087a847021345a94c7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
